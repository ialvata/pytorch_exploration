{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.0.0+cu117\n",
      "torchvision version: 0.15.1+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "print(f\"torch version: {torch.__version__}\")\n",
    "print(f\"torchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dataset (same as in 04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "from  pathlib import Path\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transforms pipeline manually (required for torchvision < 0.13)\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    # 1. Reshape all images to 224x224 (though some models may require different sizes)\n",
    "    transforms.ToTensor(), \n",
    "    # 2. Turn image values to between 0 & 1 \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "    # 3. A mean of [0.485, 0.456, 0.406] (across each colour channel)\n",
    "                         std=[0.229, 0.224, 0.225]) \n",
    "    # 4. A standard deviation of [0.229, 0.224, 0.225] (across each colour channel),\n",
    "])\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir: str, transform = None, target_transform = None):\n",
    "        # in case annotations are in a csv file, uncomment below.\n",
    "        # self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.paths = list(self.img_dir.glob(\"*/*.jpg\"))\n",
    "        self._classes = sorted(\n",
    "            entry.name for entry in os.scandir(self.img_dir) if entry.is_dir()\n",
    "        )\n",
    "        self._class_to_idx = {cls_name: i for i, cls_name in enumerate(self._classes)}\n",
    "        self._idx_to_class = {i: cls_name for i, cls_name in enumerate(self._classes)}\n",
    "\n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self._classes\n",
    "    @property\n",
    "    def class_to_idx(self):\n",
    "        return self._class_to_idx\n",
    "    @property\n",
    "    def idx_to_class(self):\n",
    "        return self._idx_to_class\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple[Image.Image|torch.Tensor, int|torch.Tensor]:\n",
    "        image = Image.open(str(self.paths[idx]))\n",
    "        label = self._class_to_idx[self.paths[idx].parent.name]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<__main__.CustomImageDataset at 0x7fa9ec7d8d60>,\n",
       " <__main__.CustomImageDataset at 0x7fa9ec7d9f30>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = \"data/pizza_steak_sushi/train\"\n",
    "test_dir = \"data/pizza_steak_sushi/test\"\n",
    "train_data_custom = CustomImageDataset(img_dir = train_dir, \n",
    "                                      transform = data_transform)\n",
    "test_data_custom = CustomImageDataset(img_dir = test_dir, \n",
    "                                     transform = data_transform)\n",
    "train_data_custom, test_data_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7fa9ec7a7d60>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fa9ec7a7a30>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader_custom = DataLoader(dataset=train_data_custom, batch_size=32, shuffle=True)\n",
    "test_dataloader_custom = DataLoader(dataset=test_data_custom, batch_size=32, shuffle=False) \n",
    "train_dataloader_custom, test_dataloader_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet_B0_Weights.IMAGENET1K_V1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # .DEFAULT = best available weights from pretraining on ImageNet\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassification(\n",
       "    crop_size=[224]\n",
       "    resize_size=[256]\n",
       "    mean=[0.485, 0.456, 0.406]\n",
       "    std=[0.229, 0.224, 0.225]\n",
       "    interpolation=InterpolationMode.BICUBIC\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_transforms = weights.transforms()\n",
    "auto_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_train_data_custom = CustomImageDataset(img_dir = train_dir, \n",
    "                                      transform = auto_transforms)\n",
    "auto_test_data_custom = CustomImageDataset(img_dir = test_dir, \n",
    "                                     transform = auto_transforms)\n",
    "auto_train_dataloader_custom = DataLoader(dataset=auto_train_data_custom, \n",
    "                                          batch_size=32, shuffle=True)\n",
    "auto_test_dataloader_custom = DataLoader(dataset=auto_test_data_custom, \n",
    "                                    batch_size=32, shuffle=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from torchmetrics import F1Score\n",
    "from tqdm.auto import tqdm\n",
    "from torch import nn\n",
    "from typing import Any\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseClass(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.train_loss_values = []\n",
    "        self.test_loss_values = []\n",
    "        self.f1_macro_train = []\n",
    "        self.f1_macro_test = []\n",
    "        self.f1_micro_train = []\n",
    "        self.f1_micro_test = []\n",
    "        self.f1_macro = F1Score(task=\"multiclass\", num_classes = num_classes,\n",
    "                          average=\"macro\")\n",
    "        self.f1_micro = F1Score(task=\"multiclass\", num_classes = num_classes,\n",
    "                          average=\"micro\")\n",
    "\n",
    "    def train_loop(self, dataloader: DataLoader, loss_fn:nn.modules.loss._Loss, \n",
    "                   optimizer: torch.optim.Optimizer) -> tuple[Any,Any,Any]:\n",
    "        size = len(dataloader.dataset) # type: ignore\n",
    "        num_batches = len(dataloader)\n",
    "        self.train()\n",
    "        train_loss,f1_macro, f1_micro = 0,0,0\n",
    "        for batch, (input, labels) in enumerate(dataloader):\n",
    "            input, labels = input.to(device), labels.to(device)\n",
    "            # CrossEntropyLoss works directly with logits as inputs\n",
    "            logits = self(input)\n",
    "            # CrossEntropyLoss expects a tensor of type long as targets.\n",
    "            # if we don't do the type casting outside the loss function, we get an error\n",
    "            labels_long = labels.to(dtype=torch.long)\n",
    "            loss = loss_fn(logits, labels_long)\n",
    "            # we'll add the loss accross batches/steps, and in the end average them.\n",
    "            # and for this, we need a new variable like train_loss to avoid  \n",
    "            # RuntimeError:Trying to backward through the graph a second time\n",
    "            train_loss += loss\n",
    "            # return rows with prob like quantities of size 6\n",
    "            pred = nn.Softmax(dim=1)(logits).argmax(dim=1) \n",
    "            f1_macro += self.f1_macro(pred, labels)\n",
    "            f1_micro += self.f1_micro(pred, labels)  \n",
    "            # also equal to self.f1(nn.Softmax(dim=1)(logits), labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # uncomment below for printing losses during batch training\n",
    "            # if batch % 100 == 0:\n",
    "            # loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            # print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        train_loss /= num_batches\n",
    "        f1_macro /= num_batches # I'm not sure about the implications of avg over f1 score...\n",
    "        f1_micro /= num_batches\n",
    "        return train_loss, f1_macro, f1_micro\n",
    "    \n",
    "    def test_loop(self, dataloader:DataLoader, \n",
    "                  loss_fn:nn.modules.loss._Loss) -> tuple[Any,Any,Any]:\n",
    "        num_batches = len(dataloader)\n",
    "        self.eval()\n",
    "        with torch.inference_mode():\n",
    "            test_loss,f1_macro, f1_micro = 0,0,0\n",
    "            for batch, (input, labels) in enumerate(dataloader):\n",
    "                input, labels = input.to(device), labels.to(device)\n",
    "                logits = self(input)\n",
    "                labels_long = labels.to(dtype=torch.long)\n",
    "                loss = loss_fn(logits, labels_long)\n",
    "                test_loss += loss\n",
    "                pred = nn.Softmax(dim=1)(logits).argmax(dim=1)\n",
    "                f1_macro += self.f1_macro(pred, labels)\n",
    "                f1_micro += self.f1_micro(pred, labels)\n",
    "            test_loss /= num_batches\n",
    "            f1_macro /= num_batches\n",
    "            f1_micro /= num_batches \n",
    "        return test_loss, f1_macro, f1_micro\n",
    "    \n",
    "    def train_model(self, dataloader:DataLoader, loss_fn:nn.modules.loss._Loss, \n",
    "                    optimizer: torch.optim.Optimizer, n_epochs:int = 100, \n",
    "                    verbose: bool = False) -> None:\n",
    "        for epoch in tqdm(range(1,n_epochs+1)):\n",
    "            train_loss, train_f1_macro, train_f1_micro = self.train_loop(\n",
    "                dataloader = dataloader, loss_fn = loss_fn, optimizer = optimizer\n",
    "            )\n",
    "            self.train_loss_values.append(train_loss.detach().cpu().numpy())\n",
    "            self.f1_macro_train.append(train_f1_macro.detach().cpu().numpy())\n",
    "            self.f1_micro_train.append(train_f1_micro.detach().cpu().numpy())\n",
    "            test_loss, test_f1_macro, test_f1_micro = self.test_loop(\n",
    "                dataloader = dataloader, loss_fn = loss_fn\n",
    "            )\n",
    "            self.test_loss_values.append(test_loss.detach().cpu().numpy())\n",
    "            self.f1_macro_test.append(train_f1_macro.detach().cpu().numpy())\n",
    "            self.f1_micro_test.append(train_f1_micro.detach().cpu().numpy())\n",
    "            if verbose:\n",
    "                print(f\"\\nEpoch {epoch}\\n-------------------------------\")\n",
    "                print(\n",
    "                    f\"{loss_fn._get_name()} Train Loss: {train_loss} |\"\n",
    "                    f\"{loss_fn._get_name()} Test Loss: {test_loss}\"\n",
    "                )\n",
    "                print(\n",
    "                    f\"F1 Train Score (macro,micro): {train_f1_macro,train_f1_micro}  |\"\n",
    "                    f\"F1 Test Score (macro,micro): {test_f1_macro,test_f1_micro}\"\n",
    "                )\n",
    "    \n",
    "    def predict(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        self.eval()\n",
    "        with torch.inference_mode():\n",
    "            logits = self(input.to(device=device, dtype=torch.float32))\n",
    "            pred = nn.Softmax(dim=1)(logits).argmax(dim=1)\n",
    "        return pred\n",
    "    \n",
    "    def evaluation_report(self, dataloader: DataLoader, labels_names: list[str]):\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for batch, (inputs_per_batch, labels_per_batch) in enumerate(dataloader):\n",
    "                y_pred.append(self.predict(inputs_per_batch).cpu().numpy())\n",
    "                y_true.append(labels_per_batch.cpu().numpy())\n",
    "        y_true_1D = np.concatenate(y_true)\n",
    "        y_pred_1D = np.concatenate(y_pred)\n",
    "        print(classification_report(y_pred = y_pred_1D, y_true = y_true_1D,\n",
    "                                target_names = labels_names))\n",
    "        \n",
    "    def plot_loss_curves(self): \n",
    "        epochs = range(len(self.test_loss_values))\n",
    "        # Setup a plot \n",
    "        plt.figure(figsize=(15, 7))\n",
    "        # Plot loss\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.plot(epochs, self.train_loss_values, label='Train')\n",
    "        plt.plot(epochs, self.test_loss_values, label='Test')\n",
    "        plt.title('Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.legend()\n",
    "\n",
    "        # Plot f1 Macro\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.plot(epochs, self.f1_macro_train, label='Train')\n",
    "        plt.plot(epochs, self.f1_macro_test, label='Test')\n",
    "        plt.title('F1 Macro')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.legend()\n",
    "\n",
    "        # Plot f1 Micro\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.plot(epochs, self.f1_micro_train, label='Train')\n",
    "        plt.plot(epochs, self.f1_micro_test, label='Test')\n",
    "        plt.title('F1 Micro')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineTunedEfficientNet(BaseClass):\n",
    "    def __init__(self, output_shape: int, device: str = \"cpu\"):\n",
    "        super().__init__(num_classes = output_shape)\n",
    "        weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT \n",
    "        # .DEFAULT = best available weights \n",
    "        self.model = torchvision.models.efficientnet_b0(weights=weights).to(device)\n",
    "        # Freezing the layer type called features.\n",
    "        for param in self.model.features.parameters():\n",
    "            param.requires_grad = False\n",
    "        # Recreate the classifier layer and seed it to the target device\n",
    "        # seeding will create a Dropout layer with the same initial weights.\n",
    "        torch.manual_seed(42)\n",
    "        torch.cuda.manual_seed(42)\n",
    "        self.model.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(p=0.2, inplace=True), # same as before\n",
    "            torch.nn.Linear(in_features=1280, # same as before\n",
    "                            out_features=output_shape, # this changes\n",
    "                            bias=True)\n",
    "        ).to(device)\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficient_finetuned = FineTunedEfficientNet(output_shape=3, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================================================================================================\n",
       "Layer (type (var_name))                                           Input Shape          Output Shape         Param #              Trainable\n",
       "=================================================================================================================================================\n",
       "FineTunedEfficientNet (FineTunedEfficientNet)                     [32, 3, 224, 224]    [32, 3]              --                   Partial\n",
       "├─EfficientNet (model)                                            [32, 3, 224, 224]    [32, 3]              --                   Partial\n",
       "│    └─Sequential (features)                                      [32, 3, 224, 224]    [32, 1280, 7, 7]     --                   False\n",
       "│    │    └─Conv2dNormActivation (0)                              [32, 3, 224, 224]    [32, 32, 112, 112]   (928)                False\n",
       "│    │    └─Sequential (1)                                        [32, 32, 112, 112]   [32, 16, 112, 112]   (1,448)              False\n",
       "│    │    └─Sequential (2)                                        [32, 16, 112, 112]   [32, 24, 56, 56]     (16,714)             False\n",
       "│    │    └─Sequential (3)                                        [32, 24, 56, 56]     [32, 40, 28, 28]     (46,640)             False\n",
       "│    │    └─Sequential (4)                                        [32, 40, 28, 28]     [32, 80, 14, 14]     (242,930)            False\n",
       "│    │    └─Sequential (5)                                        [32, 80, 14, 14]     [32, 112, 14, 14]    (543,148)            False\n",
       "│    │    └─Sequential (6)                                        [32, 112, 14, 14]    [32, 192, 7, 7]      (2,026,348)          False\n",
       "│    │    └─Sequential (7)                                        [32, 192, 7, 7]      [32, 320, 7, 7]      (717,232)            False\n",
       "│    │    └─Conv2dNormActivation (8)                              [32, 320, 7, 7]      [32, 1280, 7, 7]     (412,160)            False\n",
       "│    └─AdaptiveAvgPool2d (avgpool)                                [32, 1280, 7, 7]     [32, 1280, 1, 1]     --                   --\n",
       "│    └─Sequential (classifier)                                    [32, 1280]           [32, 3]              --                   True\n",
       "│    │    └─Dropout (0)                                           [32, 1280]           [32, 1280]           --                   --\n",
       "│    │    └─Linear (1)                                            [32, 1280]           [32, 3]              3,843                True\n",
       "=================================================================================================================================================\n",
       "Total params: 4,011,391\n",
       "Trainable params: 3,843\n",
       "Non-trainable params: 4,007,548\n",
       "Total mult-adds (G): 12.31\n",
       "=================================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 3452.09\n",
       "Params size (MB): 16.05\n",
       "Estimated Total Size (MB): 3487.41\n",
       "================================================================================================================================================="
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=efficient_finetuned, \n",
    "        input_size=(32, 3, 224, 224), # it's \"input_size\", not \"input_shape\"!\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"],\n",
    "        device = device # or \"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the loss function and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(efficient_finetuned.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:11<00:00,  2.37s/it]\n"
     ]
    }
   ],
   "source": [
    "efficient_finetuned.train_model(auto_train_dataloader_custom, loss_fn = loss_fn, \n",
    "                      optimizer = optimizer, n_epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       pizza       0.88      0.92      0.90        25\n",
      "       steak       0.70      1.00      0.83        19\n",
      "       sushi       1.00      0.71      0.83        31\n",
      "\n",
      "    accuracy                           0.85        75\n",
      "   macro avg       0.86      0.88      0.85        75\n",
      "weighted avg       0.89      0.85      0.85        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "efficient_finetuned.evaluation_report(dataloader=auto_test_dataloader_custom,\n",
    "                            labels_names = test_data_custom.classes\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have much better results with the fine-tunned model than with the tinyVGG model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
