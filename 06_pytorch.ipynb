{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.0.0+cu117\n",
      "torchvision version: 0.15.1+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "print(f\"torch version: {torch.__version__}\")\n",
    "print(f\"torchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dataset (same as in 04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "from  pathlib import Path\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transforms pipeline manually (required for torchvision < 0.13)\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    # 1. Reshape all images to 224x224 (though some models may require different sizes)\n",
    "    transforms.ToTensor(), \n",
    "    # 2. Turn image values to between 0 & 1 \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "    # 3. A mean of [0.485, 0.456, 0.406] (across each colour channel)\n",
    "                         std=[0.229, 0.224, 0.225]) \n",
    "    # 4. A standard deviation of [0.229, 0.224, 0.225] (across each colour channel),\n",
    "])\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir: str, transform = None, target_transform = None):\n",
    "        # in case annotations are in a csv file, uncomment below.\n",
    "        # self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.paths = list(self.img_dir.glob(\"*/*.jpg\"))\n",
    "        self._classes = sorted(\n",
    "            entry.name for entry in os.scandir(self.img_dir) if entry.is_dir()\n",
    "        )\n",
    "        self._class_to_idx = {cls_name: i for i, cls_name in enumerate(self._classes)}\n",
    "        self._idx_to_class = {i: cls_name for i, cls_name in enumerate(self._classes)}\n",
    "\n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self._classes\n",
    "    @property\n",
    "    def class_to_idx(self):\n",
    "        return self._class_to_idx\n",
    "    @property\n",
    "    def idx_to_class(self):\n",
    "        return self._idx_to_class\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple[Image.Image|torch.Tensor, int|torch.Tensor]:\n",
    "        image = Image.open(str(self.paths[idx]))\n",
    "        label = self._class_to_idx[self.paths[idx].parent.name]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<__main__.CustomImageDataset at 0x7f6e6d0e5480>,\n",
       " <__main__.CustomImageDataset at 0x7f6e6d09af80>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = \"data/pizza_steak_sushi/train\"\n",
    "test_dir = \"data/pizza_steak_sushi/test\"\n",
    "train_data_custom = CustomImageDataset(img_dir = train_dir, \n",
    "                                      transform = data_transform)\n",
    "test_data_custom = CustomImageDataset(img_dir = test_dir, \n",
    "                                     transform = data_transform)\n",
    "train_data_custom, test_data_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7f6e6d0e4d60>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f6e6d0e4fd0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader_custom = DataLoader(dataset=train_data_custom, batch_size=32, shuffle=True)\n",
    "test_dataloader_custom = DataLoader(dataset=test_data_custom, batch_size=32, shuffle=False) \n",
    "train_dataloader_custom, test_dataloader_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet_B0_Weights.IMAGENET1K_V1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # .DEFAULT = best available weights from pretraining on ImageNet\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassification(\n",
       "    crop_size=[224]\n",
       "    resize_size=[256]\n",
       "    mean=[0.485, 0.456, 0.406]\n",
       "    std=[0.229, 0.224, 0.225]\n",
       "    interpolation=InterpolationMode.BICUBIC\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_transforms = weights.transforms()\n",
    "auto_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_train_data_custom = CustomImageDataset(img_dir = train_dir, \n",
    "                                      transform = auto_transforms)\n",
    "auto_test_data_custom = CustomImageDataset(img_dir = test_dir, \n",
    "                                     transform = auto_transforms)\n",
    "auto_train_dataloader_custom = DataLoader(dataset=auto_train_data_custom, \n",
    "                                          batch_size=32, shuffle=True)\n",
    "test_dataloader_custom = DataLoader(dataset=auto_test_data_custom, \n",
    "                                    batch_size=32, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
