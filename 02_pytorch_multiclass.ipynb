{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivo/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchmetrics import F1Score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ipaddress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivo/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Botnet Detection\n",
    "## A Multiclass Classification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset can be found [zenodo.org/records/8035724](https://zenodo.org/records/8035724)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the research paper [An empirical comparison of botnet detection methods](https://doi.org/10.1016/j.cose.2014.05.011) we have some information on the features used.\n",
    "1. Source IP address\n",
    "2. Amount of unique source ports used by this source IP address.\n",
    "3. Amount of unique destination IP addresses contacted by this source IP address.\n",
    "4. Amount of unique destination ports contacted by this source IP address.\n",
    "5. Amount of NetFlows used by this source IP address.\n",
    "6. Amount of bytes transferred by this source IP address.\n",
    "7. Amount of packets transferred by this source IP address.\n",
    "\n",
    "After clustering some of this observations, the authors created some more features:\n",
    "1. Total amount of instances in the cluster.\n",
    "2. Total amount of NetFlows in the cluster.\n",
    "3. Amount of source IP addresses.\n",
    "4. Average amount of unique source ports.\n",
    "5. Standard Deviation of the amount of unique source ports.\n",
    "6. Average amount of unique destination IP addresses.\n",
    "7. Standard Deviation of the amount of unique destination IP addresses.\n",
    "8. Average amount of unique destination ports.\n",
    "9. Standard Deviation of the amount of unique destination ports.\n",
    "10. Average amount of NetFlows.\n",
    "11. Standard Deviation of the amount of NetFlows.\n",
    "12. Average amount of bytes transferred.\n",
    "13. Standard Deviation of the amount of bytes transferred.\n",
    "14. Average amount of packets transferred.\n",
    "15. Standard Deviation of the amount of packets transferred.\n",
    "\n",
    "The remaining features should be self-explanatory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"./data/botnet_multiclass.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 176640 entries, 0 to 176639\n",
      "Columns: 85 entries, Unnamed: 0.1 to LABEL\n",
      "dtypes: bool(4), float64(61), int64(17), object(3)\n",
      "memory usage: 109.8+ MB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(raw_data.isna()).any().any() # True means that we have missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to transform the object columns, and deal with missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = raw_data.copy(deep=True) \n",
    "# since we have enough memory, it should be ok. This will avoid messing the original data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DST_IP', 'SRC_IP', 'LABEL'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_columns = preprocessed_data.select_dtypes(include=['object'])\n",
    "object_columns.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's encode the destination and source IP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DST_IP</th>\n",
       "      <th>SRC_IP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>147.32.80.9</td>\n",
       "      <td>147.32.84.165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>147.32.84.255</td>\n",
       "      <td>147.32.84.165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>147.32.84.255</td>\n",
       "      <td>147.32.84.165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>147.32.84.165.</td>\n",
       "      <td>60.190.222.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.190.222.139.</td>\n",
       "      <td>147.32.84.165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            DST_IP          SRC_IP\n",
       "0      147.32.80.9   147.32.84.165\n",
       "1    147.32.84.255   147.32.84.165\n",
       "2    147.32.84.255   147.32.84.165\n",
       "3   147.32.84.165.  60.190.222.139\n",
       "4  60.190.222.139.   147.32.84.165"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_columns[['DST_IP', 'SRC_IP']].head()\n",
    "# notice row with index 3. There's an extra final \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ip_encoding(ip_address:str) -> int:\n",
    "    return int(ipaddress.ip_address(ip_address.rstrip(\".\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IPv4Address('147.32.84.165')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipaddress.ip_address(ip_encoding(\"147.32.84.165.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DST_IP</th>\n",
       "      <th>SRC_IP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2468368393</td>\n",
       "      <td>2468369573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2468369663</td>\n",
       "      <td>2468369573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2468369663</td>\n",
       "      <td>2468369573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2468369573</td>\n",
       "      <td>1019141771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1019141771</td>\n",
       "      <td>2468369573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DST_IP      SRC_IP\n",
       "0  2468368393  2468369573\n",
       "1  2468369663  2468369573\n",
       "2  2468369663  2468369573\n",
       "3  2468369573  1019141771\n",
       "4  1019141771  2468369573"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data['DST_IP'] = preprocessed_data['DST_IP'].apply(ip_encoding)\n",
    "preprocessed_data[\"SRC_IP\"] = preprocessed_data['SRC_IP'].apply(ip_encoding)\n",
    "preprocessed_data[['DST_IP',\"SRC_IP\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_enc = LabelEncoder()\n",
    "preprocessed_data[\"LABEL\"] = label_enc.fit_transform(preprocessed_data[\"LABEL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['clear', 'donbot', 'fast_flux', 'neris', 'qvod', 'rbot'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_enc.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The zero class represents 'normalware', whereas all the remaining classes represent some sort of malware, more specifically botnets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a small EDA on the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LABEL\n",
       "0        165573\n",
       "3          6332\n",
       "2          4367\n",
       "4           286\n",
       "5            55\n",
       "1            27\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_counts = preprocessed_data[[\"LABEL\"]].value_counts()\n",
    "labels_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_counts.plot.pie(); # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is highly imbalanced, to the point that classifying some classes could be considered as outlier detection. There will be a section focused on this problem later on.\n",
    "\n",
    "For now, we will conduct our analysis without worrying to much on the class imbalance problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150598, 85)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data[preprocessed_data.isna().any(axis=1)].shape\n",
    "# there are 150598 row whose values have at least an NaN, leaving us with \n",
    "# only 26042 rows which are completely filled. Even though torch NN can take NaNs values, \n",
    "# these will contaminate the calculations, resulting in predictions full of NaNs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep this notebook simple, I'll just drop the rows with NaN's values.\n",
    "In a more demanding setting, we should decide on an imputation method for each feature, *separately*. And depending on the chosen method, we may only apply it after we've splitted the data into train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 26042 entries, 1 to 176607\n",
      "Columns: 85 entries, Unnamed: 0.1 to LABEL\n",
      "dtypes: bool(4), float64(61), int64(20)\n",
      "memory usage: 16.4 MB\n"
     ]
    }
   ],
   "source": [
    "preprocessed_data = preprocessed_data.dropna()\n",
    "preprocessed_data.info(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating features and label\n",
    "X = torch.tensor(preprocessed_data.iloc[:,:-1].values.astype(np.float64), dtype=torch.float64)\n",
    "# torch complains about a numpy.object_, even though pandas say there's no type object.\n",
    "# so, I have to use .astype. Also, if we use something less than np.float64, \n",
    "# we'll have overflow problems, and torch will put `inf`, and this will create problems.\n",
    "y = torch.tensor(preprocessed_data[\"LABEL\"].values.astype(np.float64), dtype=torch.float64)\n",
    "# CrossEntropyLoss expects targets of 0D or 1D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([23437, 84]),\n",
       " torch.Size([23437]),\n",
       " torch.Size([2605, 84]),\n",
       " torch.Size([2605]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.9, stratify=y)\n",
    "# stratify will help keep the proportions of the classes in both y_train and y_test,\n",
    "# and thus avoid having a zero-shot classification problem on our hands.\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the distribution of the class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.764432\n",
       "3.0    0.177326\n",
       "2.0    0.049836\n",
       "4.0    0.007595\n",
       "5.0    0.000512\n",
       "1.0    0.000299\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train.numpy()).value_counts(normalize=True)\n",
    "# we have all classes in the training set, which is good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.764299\n",
       "3.0    0.177351\n",
       "2.0    0.049904\n",
       "4.0    0.007678\n",
       "1.0    0.000384\n",
       "5.0    0.000384\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_test.numpy()).value_counts(normalize=True)\n",
    "# we also have all classes in the test set, with the weights of each class being very\n",
    "# similar. This will avoid problems as distribution shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Construct a model class that subclasses nn.Module\n",
    "class BotNetClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.train_loss_values = []\n",
    "        self.test_loss_values = []\n",
    "        self.f1 = F1Score(task=\"multiclass\", num_classes=6)\n",
    "        self.layer_1 = nn.Linear(in_features=84, out_features=30, dtype=torch.float64) \n",
    "        self.layer_2 = nn.Linear(in_features=30, out_features=10, dtype=torch.float64)\n",
    "        self.layer_3 = nn.Linear(in_features=10, out_features=6, dtype=torch.float64)\n",
    "        # output should have 6 classes\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return  self.layer_3(self.relu(self.layer_2(self.relu(self.layer_1(x)))))\n",
    "    \n",
    "    def train_loop(self, input: torch.Tensor, labels: torch.Tensor, \n",
    "                   loss_fn:nn.modules.loss._Loss, optimizer: torch.optim.Optimizer):\n",
    "        self.train()\n",
    "        # Forward pass on train data using the forward() method\n",
    "        # CrossEntropyLoss works directly with logits as inputs\n",
    "        logits = self(input)\n",
    "        # CrossEntropyLoss expects a tensor of type long as targets.\n",
    "        # if we don't do the type casting outside the loss function, we get an error\n",
    "        labels_long = labels.to(dtype=torch.long)\n",
    "        loss = loss_fn(logits, labels_long)\n",
    "        # return rows with prob like quantities of size 6\n",
    "        pred = nn.Softmax(dim=1)(logits).argmax(dim=1) \n",
    "        f1_value = self.f1(pred, labels)\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        # optimize parameters\n",
    "        optimizer.step()\n",
    "        # restart cycle\n",
    "        optimizer.zero_grad()\n",
    "        return loss, f1_value\n",
    "    \n",
    "    def test_loop(self, input: torch.Tensor, labels: torch.Tensor, \n",
    "                  loss_fn:nn.modules.loss._Loss):\n",
    "        self.eval()\n",
    "        with torch.inference_mode():\n",
    "            logits = self(input)\n",
    "            labels_long = labels.to(dtype=torch.long)\n",
    "            loss = loss_fn(logits, labels_long)\n",
    "            pred = nn.Softmax(dim=1)(logits).argmax(dim=1)\n",
    "            f1_value = self.f1(pred, labels)\n",
    "        return loss, f1_value\n",
    "    \n",
    "    def train_model(self, input: torch.Tensor, labels: torch.Tensor,\n",
    "                    loss_fn:nn.modules.loss._Loss, optimizer: torch.optim.Optimizer,\n",
    "                    n_epochs:int = 100):\n",
    "        for epoch in range(1,n_epochs+1):\n",
    "            print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "            train_loss, train_f1 = self.train_loop(input = input, labels = labels, \n",
    "                                         loss_fn = loss_fn, optimizer = optimizer)\n",
    "            self.train_loss_values.append(train_loss.detach().cpu().numpy())\n",
    "            test_loss, test_f1 = self.test_loop(input = input, labels = labels, \n",
    "                                       loss_fn = loss_fn)\n",
    "            self.test_loss_values.append(test_loss.detach().cpu().numpy())\n",
    "            print(\n",
    "                f\"{loss_fn._get_name()} Train Loss: {train_loss} |\"\n",
    "                f\"{loss_fn._get_name()} Test Loss: {test_loss}\"\n",
    "            )\n",
    "            print(\n",
    "                f\"F1 Train Score: {train_f1}  | F1 Test Score: {test_f1}\"\n",
    "            )\n",
    "        print(\"Done!\")\n",
    "    \n",
    "    def predict(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        self.eval()\n",
    "        with torch.inference_mode():\n",
    "            logits = self(input)\n",
    "            pred = nn.Softmax(dim=1)(logits).argmax(dim=1)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BotNetClassifier(\n",
       "  (f1): MulticlassF1Score()\n",
       "  (layer_1): Linear(in_features=84, out_features=30, bias=True)\n",
       "  (layer_2): Linear(in_features=30, out_features=10, bias=True)\n",
       "  (layer_3): Linear(in_features=10, out_features=6, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Create an instance of the model and send it to target device\n",
    "botnet_cl = BotNetClassifier().to(device)\n",
    "botnet_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 16219541.6466, -56927594.1368,  19459940.4476,  56225135.2202,\n",
       "         -52848711.4474, -26583584.2109],\n",
       "        [  1527536.4929, -42386992.0813,  17320072.4345,  80144927.6522,\n",
       "         -43052192.9036, -26483085.4649],\n",
       "        [ 15529199.4468, -61502061.9916,  20694104.5652,  75803644.7419,\n",
       "         -69323667.8517, -30827996.1198],\n",
       "        ...,\n",
       "        [  3855499.5252, -45977489.3800,  16666083.6515,  76618050.2813,\n",
       "         -49725501.4039, -26684591.5181],\n",
       "        [ 16241216.9965, -56837179.4351,  19452177.6533,  56018482.8865,\n",
       "         -52669402.8578, -26527799.4007],\n",
       "        [ 16243865.3001, -56836782.5250,  19453129.2123,  56012788.5729,\n",
       "         -52663968.2991, -26526689.3268]], dtype=torch.float64,\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "botnet_cl(X_train.to(device)) # simple litmus test to check whether it's working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=botnet_cl.parameters(), \n",
    "                            lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 57456232.31010731 |CrossEntropyLoss Test Loss: 3.218310987491218e+30\n",
      "F1 Train Score: 0.17732645571231842  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 3.218310987491218e+30 |CrossEntropyLoss Test Loss: 346902.8379035307\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 346902.8379035307 |CrossEntropyLoss Test Loss: 1.6184206978328923\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 1.6184206978328923 |CrossEntropyLoss Test Loss: 1.579202141773818\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 1.579202141773818 |CrossEntropyLoss Test Loss: 1.541491755270979\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 1.541491755270979 |CrossEntropyLoss Test Loss: 1.505280966666175\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 1.505280966666175 |CrossEntropyLoss Test Loss: 1.470556290032149\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 1.470556290032149 |CrossEntropyLoss Test Loss: 1.4372994798967382\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 1.4372994798967382 |CrossEntropyLoss Test Loss: 1.4054877665066394\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 1.4054877665066394 |CrossEntropyLoss Test Loss: 1.3750941604965774\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 1.3750941604965774 |CrossEntropyLoss Test Loss: 1.346087814533585\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 1.346087814533585 |CrossEntropyLoss Test Loss: 1.318434428771444\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 1.318434428771444 |CrossEntropyLoss Test Loss: 1.2920966867859949\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 1.2920966867859949 |CrossEntropyLoss Test Loss: 1.2670347090339666\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 1.2670347090339666 |CrossEntropyLoss Test Loss: 1.2432065117174076\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 1.2432065117174076 |CrossEntropyLoss Test Loss: 1.2205684601497513\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 1.2205684601497513 |CrossEntropyLoss Test Loss: 1.1990757072019267\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 1.1990757072019267 |CrossEntropyLoss Test Loss: 1.1786826090490325\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 1.1786826090490325 |CrossEntropyLoss Test Loss: 1.159343112137756\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 1.159343112137756 |CrossEntropyLoss Test Loss: 1.1410111069626243\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 1.1410111069626243 |CrossEntropyLoss Test Loss: 1.1236407458035413\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 1.1236407458035413 |CrossEntropyLoss Test Loss: 1.107186722984858\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 1.107186722984858 |CrossEntropyLoss Test Loss: 1.0916045174335627\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 1.0916045174335627 |CrossEntropyLoss Test Loss: 1.0768505983241972\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 1.0768505983241972 |CrossEntropyLoss Test Loss: 1.0628825953984946\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 1.0628825953984946 |CrossEntropyLoss Test Loss: 1.049659436147503\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 1.049659436147503 |CrossEntropyLoss Test Loss: 1.037141452460355\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 1.037141452460355 |CrossEntropyLoss Test Loss: 1.025290459599028\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 1.025290459599028 |CrossEntropyLoss Test Loss: 1.0140698104774166\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 1.0140698104774166 |CrossEntropyLoss Test Loss: 1.0034444282310462\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 1.0034444282310462 |CrossEntropyLoss Test Loss: 0.9933808199852118\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 32\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossEntropyLoss Train Loss: 0.9933808199852118 |CrossEntropyLoss Test Loss: 0.9838470745863791\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.9838470745863791 |CrossEntropyLoss Test Loss: 0.9748128468739633\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.9748128468739633 |CrossEntropyLoss Test Loss: 0.9662493308536151\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.9662493308536151 |CrossEntropyLoss Test Loss: 0.9581292239024459\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.9581292239024459 |CrossEntropyLoss Test Loss: 0.9504266839020291\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.9504266839020291 |CrossEntropyLoss Test Loss: 0.9431172809645522\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.9431172809645522 |CrossEntropyLoss Test Loss: 0.9361779451972201\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.9361779451972201 |CrossEntropyLoss Test Loss: 0.9295869117438418\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.9295869117438418 |CrossEntropyLoss Test Loss: 0.9233236641531065\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.9233236641531065 |CrossEntropyLoss Test Loss: 0.9173688769515317\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.9173688769515317 |CrossEntropyLoss Test Loss: 0.9117043581459122\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.9117043581459122 |CrossEntropyLoss Test Loss: 0.9063129922449222\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.9063129922449222 |CrossEntropyLoss Test Loss: 0.9011786842715274\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.9011786842715274 |CrossEntropyLoss Test Loss: 0.8962863051359464\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8962863051359464 |CrossEntropyLoss Test Loss: 0.8916216386516832\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8916216386516832 |CrossEntropyLoss Test Loss: 0.8871713304032786\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8871713304032786 |CrossEntropyLoss Test Loss: 0.8829228386124311\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8829228386124311 |CrossEntropyLoss Test Loss: 0.8788643870976259\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8788643870976259 |CrossEntropyLoss Test Loss: 0.8749849203801001\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8749849203801001 |CrossEntropyLoss Test Loss: 0.8712740609545434\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8712740609545434 |CrossEntropyLoss Test Loss: 0.8677220687153939\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8677220687153939 |CrossEntropyLoss Test Loss: 0.864319802507779\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.864319802507779 |CrossEntropyLoss Test Loss: 0.8610586837553057\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8610586837553057 |CrossEntropyLoss Test Loss: 0.8579306621041264\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8579306621041264 |CrossEntropyLoss Test Loss: 0.8549281830133761\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8549281830133761 |CrossEntropyLoss Test Loss: 0.8520441572155397\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8520441572155397 |CrossEntropyLoss Test Loss: 0.8492719319661026\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8492719319661026 |CrossEntropyLoss Test Loss: 0.8466052639994599\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8466052639994599 |CrossEntropyLoss Test Loss: 0.8440382941072281\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8440382941072281 |CrossEntropyLoss Test Loss: 0.8415655232553839\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8415655232553839 |CrossEntropyLoss Test Loss: 0.8391817901579232\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8391817901579232 |CrossEntropyLoss Test Loss: 0.8368822502266487\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8368822502266487 |CrossEntropyLoss Test Loss: 0.8346623558191512\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8346623558191512 |CrossEntropyLoss Test Loss: 0.8325178377099007\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8325178377099007 |CrossEntropyLoss Test Loss: 0.8304446877124219\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8304446877124219 |CrossEntropyLoss Test Loss: 0.828439142383795\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.828439142383795 |CrossEntropyLoss Test Loss: 0.8264976677460416\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8264976677460416 |CrossEntropyLoss Test Loss: 0.8246169449622918\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8246169449622918 |CrossEntropyLoss Test Loss: 0.8227938569089792\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8227938569089792 |CrossEntropyLoss Test Loss: 0.8210254755885317\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8210254755885317 |CrossEntropyLoss Test Loss: 0.8193090503302306\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8193090503302306 |CrossEntropyLoss Test Loss: 0.8176419967299542\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8176419967299542 |CrossEntropyLoss Test Loss: 0.8160218862824615\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8160218862824615 |CrossEntropyLoss Test Loss: 0.8144464366626994\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8144464366626994 |CrossEntropyLoss Test Loss: 0.8129135026152586\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8129135026152586 |CrossEntropyLoss Test Loss: 0.8114210674136796\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8114210674136796 |CrossEntropyLoss Test Loss: 0.8099672348536667\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8099672348536667 |CrossEntropyLoss Test Loss: 0.8085502217465648\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8085502217465648 |CrossEntropyLoss Test Loss: 0.8071683508815727\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8071683508815727 |CrossEntropyLoss Test Loss: 0.8058200444271558\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8058200444271558 |CrossEntropyLoss Test Loss: 0.8045038177440343\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8045038177440343 |CrossEntropyLoss Test Loss: 0.8032182735838655\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8032182735838655 |CrossEntropyLoss Test Loss: 0.8019620966493826\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8019620966493826 |CrossEntropyLoss Test Loss: 0.8007340484933447\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.8007340484933447 |CrossEntropyLoss Test Loss: 0.7995329627350447\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.7995329627350447 |CrossEntropyLoss Test Loss: 0.7983577405745231\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.7983577405745231 |CrossEntropyLoss Test Loss: 0.7972073465858794\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.7972073465858794 |CrossEntropyLoss Test Loss: 0.7960808047722651\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.7960808047722651 |CrossEntropyLoss Test Loss: 0.7949771948662497\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.7949771948662497 |CrossEntropyLoss Test Loss: 0.7938956488602846\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.7938956488602846 |CrossEntropyLoss Test Loss: 0.7928353477529623\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.7928353477529623 |CrossEntropyLoss Test Loss: 0.7917955184976638\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.7917955184976638 |CrossEntropyLoss Test Loss: 0.790775431141045\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.790775431141045 |CrossEntropyLoss Test Loss: 0.7897743961395904\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.7897743961395904 |CrossEntropyLoss Test Loss: 0.788791761843214\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.788791761843214 |CrossEntropyLoss Test Loss: 0.7878269121355661\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.7878269121355661 |CrossEntropyLoss Test Loss: 0.7868792642213657\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.7868792642213657 |CrossEntropyLoss Test Loss: 0.7859482665516672\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "CrossEntropyLoss Train Loss: 0.7859482665516672 |CrossEntropyLoss Test Loss: 0.7850333968785472\n",
      "F1 Train Score: 0.7644323110580444  | F1 Test Score: 0.7644323110580444\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "botnet_cl.train_model(input= X_train.to(device), labels=y_train.to(device), \n",
    "                      loss_fn=loss_fn, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the F1 score, and Loss, we'll see that they are very similar, if not equal, on both train and test set. This is odd..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2605\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "botnet_predictions = botnet_cl.predict(X_test.to(device))\n",
    "pd.DataFrame(botnet_predictions.cpu().numpy()).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, due to the imbalanced dataset, the botnet_cl decided to classify all test observations as 'normalware'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Possible Avenues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are some common approaches to address class imbalance in multi-class classification:\n",
    "\n",
    "**Resampling Techniques**:\n",
    "- Oversampling, or creating synthetic samples of the minority classes(e.g. SMOTE or ADASYN). This may lead to addition of noise.\n",
    "- Undersampling the instances in the majority class. This may lead to loss of crucial information.\n",
    "We may try to use [imbalanced-learn](https://imbalanced-learn.org/stable/index.html)\n",
    "\n",
    "**Weighted Loss Function**:\n",
    "We can give more importance to minority classes during training, by tweeking the weight parameter in the `torch.nn.CrossEntropyLoss`` function. I've experimented this, and in an isolated manner, it's not sufficient.\n",
    "\n",
    "**Ensemble Methods**:\n",
    "Ensemble methods (bagging, boosting, stacking, voting, or weighted avg), can improve performance on imbalance datasets. Maybe trying [Ensemble-PyTorch](https://ensemble-pytorch.readthedocs.io/en/latest/index.html)\n",
    "\n",
    "**Anomaly Detection**:\n",
    "Treat the minority classes as an anomaly/outlier detection problem.\n",
    "\n",
    "**Data Augmentation**:\n",
    "Augment the minority class data by applying various data augmentation techniques such as rotation, scaling, or adding noise. This can increase the diversity of the minority class samples.\n",
    "\n",
    "**Transfer Learning**:\n",
    "Utilize pre-trained models and fine-tune them on your imbalanced dataset. Transfer learning can be especially useful when you have limited data for the minority classes.\n",
    "\n",
    "**Combine Classes**:\n",
    "Merge similar classes to reduce the number of classes, making the problem more balanced.\n",
    "Well, we could merge all malware classes into one, and transform this into a binary classification problem.\n",
    "\n",
    "**Evaluate Performance Metrics**:\n",
    "Instead of using accuracy as the sole performance metric, consider using metrics like precision, recall, F1-score, or area under the ROC curve (AUC) that provide a better understanding of the model's performance on imbalanced data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
